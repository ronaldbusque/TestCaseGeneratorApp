[1mdiff --git a/package.json b/package.json[m
[1mindex d353e25..6f4c095 100644[m
[1m--- a/package.json[m
[1m+++ b/package.json[m
[36m@@ -29,6 +29,7 @@[m
     "react-markdown": "^9.0.1",[m
     "tailwind-merge": "^2.2.1",[m
     "tailwindcss": "3.4.1",[m
[32m+[m[32m    "tesseract.js": "^5.0.5",[m
     "typescript": "5.3.3"[m
   },[m
   "devDependencies": {[m
[1mdiff --git a/src/lib/services/ai/gemini.ts b/src/lib/services/ai/gemini.ts[m
[1mindex 2d35032..08ae4d7 100644[m
[1m--- a/src/lib/services/ai/gemini.ts[m
[1m+++ b/src/lib/services/ai/gemini.ts[m
[36m@@ -1,9 +1,8 @@[m
[31m-import { GoogleGenerativeAI, GenerativeModel, Part } from "@google/generative-ai";[m
 import { AIService, TestCaseGenerationRequest, TestCaseGenerationResponse, ModelType } from '@/lib/types';[m
 [m
 export class GeminiService implements AIService {[m
[31m-  private genAI: GoogleGenerativeAI;[m
[31m-  private model: GenerativeModel;[m
[32m+[m[32m  private readonly API_KEY: string;[m
[32m+[m[32m  private readonly API_ENDPOINT = 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-thinking-exp-01-21:generateContent';[m
   private debugLog: string[] = [];[m
 [m
   private log(message: string, data?: any) {[m
[36m@@ -17,11 +16,10 @@[m [mexport class GeminiService implements AIService {[m
     if (!apiKey) {[m
       throw new Error('NEXT_PUBLIC_GEMINI_API_KEY is not configured');[m
     }[m
[31m-    this.genAI = new GoogleGenerativeAI(apiKey);[m
[31m-    this.model = this.genAI.getGenerativeModel({ model: "gemini-2.0-flash-thinking-exp-01-21" });[m
[32m+[m[32m    this.API_KEY = apiKey;[m
   }[m
 [m
[31m-  private async fileToGenerativePart(file: File): Promise<Part> {[m
[32m+[m[32m  private async fileToGenerativePart(file: File): Promise<any> {[m
     if (file.type.startsWith('image/')) {[m
       const arrayBuffer = await file.arrayBuffer();[m
       return {[m
[36m@@ -48,7 +46,7 @@[m [mexport class GeminiService implements AIService {[m
   async generateTestCases(request: TestCaseGenerationRequest): Promise<TestCaseGenerationResponse> {[m
     this.debugLog = [];[m
     try {[m
[31m-      const parts: Part[] = [];[m
[32m+[m[32m      const parts: any[] = [];[m
 [m
       // Add files if present[m
       if (request.files && request.files.length > 0) {[m
[36m@@ -92,20 +90,31 @@[m [mIMPORTANT:[m
 [m
       this.log('System Prompt', prompt);[m
 [m
[31m-      const result = await this.model.generateContent({[m
[31m-        contents: [{[m
[31m-          role: 'user',[m
[31m-          parts[m
[31m-        }],[m
[31m-        generationConfig: {[m
[31m-          temperature: 0.1,[m
[31m-          maxOutputTokens: 15000,[m
[31m-          topK: 40,[m
[31m-          topP: 0.8,[m
[31m-        }[m
[32m+[m[32m      const response = await fetch(`${this.API_ENDPOINT}?key=${this.API_KEY}`, {[m
[32m+[m[32m        method: 'POST',[m
[32m+[m[32m        headers: {[m
[32m+[m[32m          'Content-Type': 'application/json',[m
[32m+[m[32m        },[m
[32m+[m[32m        body: JSON.stringify({[m
[32m+[m[32m          contents: [{[m
[32m+[m[32m            parts[m
[32m+[m[32m          }],[m
[32m+[m[32m          generationConfig: {[m
[32m+[m[32m            temperature: 0.1,[m
[32m+[m[32m            maxOutputTokens: 15000,[m
[32m+[m[32m            topK: 40,[m
[32m+[m[32m            topP: 0.8,[m
[32m+[m[32m          }[m
[32m+[m[32m        })[m
       });[m
 [m
[31m-      const content = result.response.text().trim();[m
[32m+[m[32m      if (!response.ok) {[m
[32m+[m[32m        const errorText = await response.text();[m
[32m+[m[32m        throw new Error(`API request failed: ${errorText}`);[m
[32m+[m[32m      }[m
[32m+[m
[32m+[m[32m      const data = await response.json();[m
[32m+[m[32m      const content = data.candidates[0].content.parts[0].text.trim();[m
       this.log('Raw Response', content);[m
 [m
       // Try to extract JSON if there's any extra text[m
[36m@@ -154,8 +163,24 @@[m [mIMPORTANT:[m
 [m
   async generateContent(prompt: string, model: ModelType): Promise<string> {[m
     try {[m
[31m-      const result = await this.model.generateContent(prompt);[m
[31m-      return result.response.text();[m
[32m+[m[32m      const response = await fetch(`${this.API_ENDPOINT}?key=${this.API_KEY}`, {[m
[32m+[m[32m        method: 'POST',[m
[32m+[m[32m        headers: {[m
[32m+[m[32m          'Content-Type': 'application/json',[m
[32m+[m[32m        },[m
[32m+[m[32m        body: JSON.stringify({[m
[32m+[m[32m          contents: [{[m
[32m+[m[32m            parts: [{ text: prompt }][m
[32m+[m[32m          }][m
[32m+[m[32m        })[m
[32m+[m[32m      });[m
[32m+[m
[32m+[m[32m      if (!response.ok) {[m
[32m+[m[32m        throw new Error(`API request failed: ${await response.text()}`);[m
[32m+[m[32m      }[m
[32m+[m
[32m+[m[32m      const data = await response.json();[m
[32m+[m[32m      return data.candidates[0].content.parts[0].text;[m
     } catch (error: any) {[m
       console.error('Gemini API error:', error);[m
       throw new Error(`Failed to generate content: ${error.message}`);[m
[1mdiff --git a/src/lib/services/ai/o1mini.ts b/src/lib/services/ai/o1mini.ts[m
[1mindex 7c6d3eb..554031b 100644[m
[1m--- a/src/lib/services/ai/o1mini.ts[m
[1m+++ b/src/lib/services/ai/o1mini.ts[m
[36m@@ -1,12 +1,108 @@[m
 import { AIService, TestCaseGenerationRequest, TestCaseGenerationResponse, ModelType } from '@/lib/types';[m
[32m+[m[32mimport { parseDocument } from '@/lib/services/documentParser';[m
 [m
 export class O1MiniService implements AIService {[m
   private readonly API_URL = process.env.NEXT_PUBLIC_OPENAI_API_URL;[m
   private readonly API_KEY = process.env.NEXT_PUBLIC_OPENAI_API_KEY;[m
[32m+[m[32m  private debugLog: string[] = [];[m
[32m+[m
[32m+[m[32m  private log(message: string, type: 'info' | 'error' | 'success' = 'info', data?: any) {[m
[32m+[m[32m    const timestamp = new Date().toISOString();[m
[32m+[m[32m    const emoji = type === 'info' ? 'ðŸ“‹' : type === 'error' ? 'ðŸ”´' : 'âœ…';[m
[32m+[m[32m    const prefix = `[${timestamp}] ${emoji} O1-Mini:`;[m
[32m+[m[41m    [m
[32m+[m[32m    console.group(prefix + ' ' + message);[m
[32m+[m[32m    if (data) {[m
[32m+[m[32m      console.log(JSON.stringify(data, null, 2));[m
[32m+[m[32m    }[m
[32m+[m[32m    console.groupEnd();[m
[32m+[m[32m  }[m
[32m+[m
[32m+[m[32m  private async processFiles(files: File[]): Promise<string> {[m
[32m+[m[32m    this.log('Starting file processing', 'info', { fileCount: files.length });[m
[32m+[m[32m    const processedContents: string[] = [];[m
[32m+[m
[32m+[m[32m    for (const file of files) {[m
[32m+[m[32m      this.log('Processing file', 'info', {[m[41m [m
[32m+[m[32m        fileName: file.name,[m
[32m+[m[32m        fileType: file.type,[m
[32m+[m[32m        fileSize: file.size[m
[32m+[m[32m      });[m
[32m+[m
[32m+[m[32m      try {[m
[32m+[m[32m        if (file.type.startsWith('image/')) {[m
[32m+[m[32m          this.log('Processing image file', 'info', { fileName: file.name });[m
[32m+[m[32m          const imageInfo = await this.analyzeImage(file);[m
[32m+[m[32m          processedContents.push(imageInfo);[m
[32m+[m[32m          this.log('Image processing complete', 'success', { fileName: file.name, imageInfo });[m
[32m+[m[32m        } else {[m
[32m+[m[32m          this.log('Processing document file', 'info', { fileName: file.name });[m
[32m+[m[32m          const textContent = await parseDocument(file);[m
[32m+[m[32m          if (textContent) {[m
[32m+[m[32m            processedContents.push(`Content from ${file.name}:\n${textContent}`);[m
[32m+[m[32m            this.log('Document processing complete', 'success', {[m[41m [m
[32m+[m[32m              fileName: file.name,[m
[32m+[m[32m              contentLength: textContent.length[m
[32m+[m[32